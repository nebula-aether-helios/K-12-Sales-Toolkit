Implementation Plan
5 minutes ago
ğŸ„ ENRICHMENT MIGRATION SCRIPT â€” BLUEPRINT (v3)
Mode: ğŸ“– READ-ONLY PLAN
Prereqs delivered (by other agent): enrichment_models.py, db_init.py
Next deliverable: 
scripts/migrate_to_enrichment_db.py

Current State
Asset	Status	Location
enrichment_models.py	âœ… Created	Correct workspace (via other agent)
db_init.py	âœ… Created	Correct workspace (via other agent)
ferengi_enrichment.db	ğŸ“Š Legacy flat DB	./outputs/ferengi_enrichment.db (12.1 MB, 9,739 rows, 159 columns)
Source manifests	ğŸ“‹ 6 JSON files	catalog_api/sources/*.json
ferengi_master_catalog.json
ğŸ“‹ 5 endpoint entries	
./outputs/ferengi_master_catalog.json
Progress snapshots	ğŸ“‹ JSON	./outputs/recursive_snapshot_*.json
CSLB CSV	ğŸ“‹ Seed data	
sacramento_contractors_cslb_sac.csv
 (9,739 rows)
IMPORTANT

All JSON files in this repo contain trailing git diff metadata (e.g.  28 changes: 28 additions & 0 deletions28). The migration script parser must strip trailing non-JSON lines before json.loads().

Migration Script Design: 
scripts/migrate_to_enrichment_db.py
CLI Interface
python scripts/migrate_to_enrichment_db.py --dry-run           # Preview counts only
python scripts/migrate_to_enrichment_db.py --apply             # Execute migration
python scripts/migrate_to_enrichment_db.py --apply --target ./out.db
python scripts/migrate_to_enrichment_db.py --apply --legacy-db ./outputs/ferengi_enrichment.db
Flag	Default	Purpose
--dry-run / --apply	required, mutually exclusive	Preview vs execute
--target	./outputs/enrichment.db	New normalized DB path
--legacy-db	./outputs/ferengi_enrichment.db	Source flat DB
4 Migration Steps
Step 1 â€” Source Manifests â†’ source_manifests table
Source File	slug	type
ca_la_accessors_manifest.json
(from api_slug field)	assessor
county_of_los_angeles_open_data.json
(from api_slug)	socrata
dca_manifest.json
(from api_slug)	api
la_city_geohub.json
(from api_slug)	geohub
osha_github_manifest.json
github.oshadata	github
sacramento_cslb_manifest.json
csv.sacramento_cslb	csv
ferengi_master_catalog.json
 endpoints (Ã—5)	ferengi.{name}	endpoint_registry
Upsert: ON CONFLICT(slug) DO UPDATE SET config_json = excluded.config_json

Step 2 â€” Legacy DB â†’ contractors + enrichment_results
The 159-column flat contractors table decomposes into:

A) Core contractors row (identity + metadata):

license_number â†’ contractors.license_number (UNIQUE)
business_name, dba_name, phone_business, address_*, status_*, risk_*
Plus packed JSON columns:

triggers_json â† 13 trigger_* columns
reports_json â† 10 report_* columns
metadata_json â† seg_*, law_*, crm_*, mongo_tag, data_source, market, record_*
B) Per-source enrichment_results rows (one row per contractor Ã— source):

source key	Phase	Columns extracted	_enriched_at
google_places
2	gp_place_id, gp_website, gp_rating, gp_review_count, gp_phone_verified, gp_hours, gp_lat, gp_lng	gp_enriched_at
osha_enforcement
2	osha_inspection_count, osha_violation_count, osha_penalty_total, osha_last_inspection_date, osha_open_cases, osha_serious_violations	osha_enriched_at
arcgis_permits
2	permit_active_count, permit_total_value, permit_last_issued_date, permit_types	permit_enriched_at
craigslist_recondon
3	cl_ad_found, cl_ad_url, cl_license_displayed, cl_down_payment_violation, cl_disaster_zone_ad + 25 more cl_*	cl_enriched_at
osint_social	1	osint_email_discovered, osint_email_verified, osint_cell_phone, osint_linkedin_url, osint_facebook_url, osint_yelp_url, osint_bbb_rating	osint_enriched_at
court_records	4	court_case_count, court_lien_count, court_judgment_total, court_bankruptcy	court_enriched_at
Skip logic: If a source has all-empty/zero/False columns AND enrich_{source}_done == False, skip creating that enrichment_results row.

Upsert: ON CONFLICT(contractor_id, source) DO UPDATE SET result_json = excluded.result_json

Batch processing: 500 rows per commit to balance memory and write throughput.

Step 3 â€” Progress Snapshots â†’ progress_snapshots
File	Fields extracted
recursive_snapshot_001.json
iteration, counts.total, counts.completed, counts.errors, computed completion_rate
enrichment_analysis.json
total_records, completed, errors, completion_rate
Step 4 â€” CSV Seed Fallback
If ferengi_enrichment.db is missing, seed contractors from 
sacramento_contractors_cslb_sac.csv
 using ON CONFLICT(license_number) DO NOTHING (no enrichment results in this mode).

JSON Parser Strategy
All JSON files in this repo have trailing diff metadata. The parser should:

python
def parse_dirty_json(text: str) -> dict:
    text = text.strip()
    try:
        return json.loads(text)          # Fast path: clean JSON
    except json.JSONDecodeError:
        pass
    lines = text.splitlines()            # Strip lines from end
    for trim in range(1, min(len(lines), 10)):
        candidate = "\n".join(lines[:len(lines) - trim]).strip()
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            continue
    raise json.JSONDecodeError("Cannot parse", text, 0)
Windows Compatibility
Add UTF-8 stdout reconfiguration at top to prevent UnicodeEncodeError with emoji output on Windows CP1252:

python
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")
Expected Dry-Run Output
ğŸ„ MARIO MIGRATION PIPE â€” DRY RUN ğŸ”
  Target: ./outputs/enrichment.db
  ğŸŒ WORLD 0: Loading source manifests...
    ğŸ“‹ github.oshadata             (github)
    ğŸ“‹ csv.sacramento_cslb         (csv)
    ğŸ“‹ ferengi.google_places_api   (endpoint_registry)
    ... (11 total)
    âœ… 11 manifests loaded
  ğŸŒ WORLD 1-4: Migrating legacy ferengi_enrichment.db...
    ğŸ“Š Found 9,739 contractors in legacy DB (159 columns)
    ğŸƒ Batch 4: 2,000 contractors, ~10,000 results
    ...
    âœ… Migrated 9,739 contractors, ~40,000 enrichment results
  ğŸŒ BONUS: Loading progress snapshots...
    ğŸ“Š recursive_snapshot_001.json: iter=1 9739/9739 (100.0%)
    âœ… 2 snapshots loaded
  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ğŸ° MIGRATION SUMMARY â€” DRY RUN ğŸ”
  Contractors migrated:       9,739
  Enrichment results:       ~40,000
  Source manifests:              11
  Progress snapshots:             2
  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Verification Checklist (post-apply)
sql
-- Row counts
SELECT 'contractors' AS tbl, COUNT(*) FROM contractors
UNION ALL SELECT 'enrichment_results', COUNT(*) FROM enrichment_results
UNION ALL SELECT 'source_manifests', COUNT(*) FROM source_manifests
UNION ALL SELECT 'progress_snapshots', COUNT(*) FROM progress_snapshots;
-- Enrichment coverage per source
SELECT source, COUNT(*) AS ct, SUM(success) AS ok
FROM enrichment_results GROUP BY source;
-- Spot-check: V3 Electric (known OSHA+CL hits)
SELECT c.license_number, c.business_name, e.source, e.result_json
FROM contractors c JOIN enrichment_results e ON c.id = e.contractor_id
WHERE c.license_number = '1000573';
Next Steps After Migration Script
Run Unit Tests (Option A): Validate migration logic with pytest.
Run --dry-run: Verify counts match (9,739 contractors, ~40K results, 11 manifests).
Run --apply: Create enrichment.db.
Option B: Adapter registry skeleton that writes enrichment outputs to the new enrichment_results table.
ğŸ„ ENRICHMENT MIGRATION VERIFICATION PLAN (Option A)
Mode: ğŸ“– READ-ONLY PLAN
Previous: 
scripts/migrate_to_enrichment_db.py
 delivered externally.
Goal: Validate migration logic via unit tests & dry-run fixtures before execution.

ğŸ§ª Verification Strategy
We cannot risk data loss or corruption during the migration of 9,739 contractors and ~40k enrichment results. Option A prescribes a rigorous testing phase:

Model Unit Tests: Verify SQLAlchemy constraints, Pydantic validation, and helper methods (e.g. upsert_contractor, upsert_enrichment_result).
Migration Dry-Run Tests: Run the full migration script against a mock legacy DB and verify precise output counts and data fidelity.
JSON Parser Tests: Fuzz-test parse_dirty_json() with various "git diff" artifacts.
ğŸ“‚ Test File Structure
tests/
â”œâ”€â”€ conftest.py                # Pytest fixtures (temporary DBs, mock paths)
â”œâ”€â”€ test_models.py             # ORM & Pydantic tests
â””â”€â”€ test_migration_dryrun.py   # Full script integration tests
1. tests/conftest.py
Defines reusable fixtures:

mock_legacy_db(tmp_path): Creates a SQLite DB with the exact 159-column schema and seeded header row + 5 sample rows (covering edge cases like empty JSON, missing fields).
mock_manifests_dir(tmp_path): Creates dummy catalog_api/sources/*.json files, some with trailing diff metadata.
mock_outputs_dir(tmp_path): Creates dummy 
ferengi_master_catalog.json
 and recursive_snapshot_*.json.
2. tests/test_models.py
Verifies enrichment_models.py:

Contractor Upsert: Ensure upsert_contractor correctly updates existing records vs inserts new ones (ON CONFLICT behavior).
Enrichment Result Upsert: Verify upsert_enrichment_result correctly handles the composite unique key 
(contractor_id, source)
.
Relationships: Confirm contractor.enrichment_results relationship loads correctly.
Cache Expiry: Test EnrichmentCache expiry logic (if implemented).
3. tests/test_migration_dryrun.py
Verifies 
scripts/migrate_to_enrichment_db.py
:

python
def test_full_migration_flow(mock_legacy_db, mock_manifests_dir, mock_outputs_dir, tmp_path):
    # Setup
    target_db = tmp_path / "target.db"
    migrator = Migrator(
        target_path=str(target_db),
        dry_run=False,
        legacy_db_path=mock_legacy_db
    )
    
    # Execute
    migrator.run()
    
    # Assertions
    conn = sqlite3.connect(target_db)
    
    # 1. Source Manifests
    assert conn.execute("SELECT COUNT(*) FROM source_manifests").fetchone()[0] == 6
    if conn.execute("SELECT COUNT(*) FROM source_manifests").fetchone()[0] != 6:
        # Check if ferengi_master_catalog endpoint entries were also loaded
        pass
    
    # 2. Contractors
    assert conn.execute("SELECT COUNT(*) FROM contractors").fetchone()[0] == 5
    
    # 3. Enrichment Results
    # Check specific row data fidelity
    row = conn.execute("SELECT result_json FROM enrichment_results WHERE source='google_places'").fetchone()
    data = json.loads(row[0])
    assert data['gp_place_id'] == 'ChIJ...' 
    
    # 4. Progress Snapshots
    assert conn.execute("SELECT COUNT(*) FROM progress_snapshots").fetchone()[0] == 2
ğŸ” Key Edge Cases to Cover
JSON Parser:
Input: {"foo": "bar"} \n 28 changes: ... -> Output: {"foo": "bar"}
Input: {"invalid":  -> Output: JSONDecodeError
Missing Fields:
Legacy row with missing license_number -> Skip
Legacy row with empty enrichment cols -> Skip creating enrichment_results
Data Types:
String "None" / "False" in legacy DB -> Convert to None / 0 / False in new DB.
âœ… Success Criteria
pytest tests/ passes with 100% coverage of migration logic.
Dry-run output matches expectations for sample data.
No UnicodeEncodeError on Windows during test runs.
ğŸš€ PHASE 3: ADAPTER IMPLEMENTATION
Mode: ğŸ“– READ-ONLY PLAN Goal: Implement "Boss Level" adapters for full enrichment coverage.

1. Adapter Strategy
Each adapter inherits from EnrichmentAdapter (base.py) and implements:

enrich(contractor)
: Fetches data, returns result dict + success bool.
fingerprint(result): Returns unique hash of result data.
health_check(): Verifies external API/source availability.
2. Priority Adapters (Worlds 1-4)
ğŸ•µï¸ ReconDon Adapter (World 1 & 3)
Target: Craigslist Scraper & OSINT

Description: wrappers existing 
recondon
 tools or implements new scraping logic.
Input: contractor.business_name, contractor.phone, contractor.license_number.
Output:
cl_ad_found (bool)
cl_ad_urls (list)
violations_detected (list)
osint_social_profiles (dict)
ğŸ—ï¸ OSHA Adapter (World 2)
Target: OSHA Enforcement API / GitHub Data

Description: Lookups against github.oshadata or DOL API.
Input: contractor.business_name.
Logic: Fuzzy match business name against OSHA violator index.
Output:
inspection_count
violation_count
penalty_total
last_inspection_date
ğŸ—ºï¸ ArcGIS Adapter (World 2)
Target: Local Building Permits

Description: Query CSLB/County GIS layers for active permits.
Input: contractor.address_*, contractor.license_number.
Output:
permit_active_count
recent_permit_values
âš–ï¸ Court Records Adapter (World 4)
Target: Superior Court Index

Description: Check for judgments/liens.
Input: contractor.license_number, contractor.business_name.
Output:
judgment_count
bankruptcy_found (bool)
ğŸ“… Next Steps for This Phase
Skeleton Implementation: Create adapters/recondon.py, adapters/osha.py, etc.
Logic Porting: Move logic from ferengi_full_enrichment.py (legacy) into these classes.
Integration: register all adapters in adapters/__init__.py.
Runner: Create scripts/run_enrichment_worker.py to pick up jobs and run adapters.