{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cb6ebed507fdb5",
   "metadata": {},
   "source": "# \ud83d\udcc8 From Chalkboard to Quota Crusher\n## How a K-8 Teacher Became a Top-10% SDR Using Data Science\n---\n**Author:** [Your Name]  \n**Purpose:** Authentic, data-driven narrative of my career transition \u2014  \ndemonstrating sales execution, education domain expertise, and technical skills  \nfor the **Sales Executive, K-8 Partnerships** role at [Literacy Partners](https://literacypartners.com)\n\n---\n> *\"I left the classroom to change more lives. Sales lets me do that at scale.\"*\n\n---\n### What This Notebook Is\nThis is my story \u2014 told honestly, with real numbers (anonymized where needed), and with  \nthe code that made it possible. It is not a resume. It is proof of work.\n\n**Three things you will see:**\n1. Why I made this transition (and why it makes me a better sales rep)\n2. The data science tools I built that took me from struggling \u2192 top 10%\n3. Exactly how I would apply this at Literacy Partners in the first 90 days\n"
  },
  {
   "cell_type": "markdown",
   "id": "d8850680f6ecc8fc",
   "metadata": {},
   "source": "## \ud83d\udd27 Setup"
  },
  {
   "cell_type": "code",
   "id": "ae20210f5d70f0a5",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Fix sys.path to include src directory\nimport os\nimport sys\n_nb_dir = os.path.dirname(os.path.abspath('__file__'))\n_repo_root = os.path.abspath(os.path.join(_nb_dir, '..'))\nsys.path.insert(0, os.path.join(_repo_root, 'src'))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nfrom matplotlib.gridspec import GridSpec\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nBRAND = {\"primary\": \"#2E4057\", \"secondary\": \"#048A81\", \"accent\": \"#F18F01\",\n         \"danger\": \"#C73E1D\", \"teacher\": \"#6C63FF\"}\nprint(\"Setup complete.\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "30d8ea9979a70ea9",
   "metadata": {},
   "source": "## \ud83c\udf4e Chapter 1: Why I Left the Classroom\n\n> **[HUMAN NARRATIVE SECTION \u2014 Jules: Leave this cell as-is]**\n>\n> This section will be written by the author with authentic personal story.\n>\n> **Prompts to address:**\n> - The moment you realized you wanted more reach/impact\n> - What you learned about communication, curriculum design, persuasion as a teacher\n> - The decision to transition (was it scary? what made you commit?)\n> - What surprised you about sales coming from education\n> - What you brought FROM teaching that made you good at sales\n>\n> **Target length:** 3\u20134 paragraphs, conversational tone, specific stories preferred.\n>\n> **Key message:** I did not leave education. I expanded my classroom.\n"
  },
  {
   "cell_type": "markdown",
   "id": "bb1bd1320401c048",
   "metadata": {},
   "source": "## \ud83d\udcde Chapter 2: The SDR Grind \u2014 Honest Numbers"
  },
  {
   "cell_type": "code",
   "id": "48e5fe2916c47d30",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ============================================================\n# MY SDR PERFORMANCE DATA (Anonymized/adjusted)\n# Replace with your actual numbers before publishing\n# ============================================================\n\n# Monthly performance data \u2014 Year 1 and Year 2\nmonthly_data = pd.DataFrame({\n    \"month\": pd.date_range(\"2024-01-01\", periods=18, freq=\"MS\"),\n    \"quota_attainment_pct\": [\n        # Year 1: Struggle \u2192 Breakthrough\n        45, 52, 61, 68, 72, 78,\n        # Breakthrough: Data science tools deployed Month 7\n        95, 108, 115, 122, 127, 119,\n        # Year 2: Consistent excellence\n        128, 134, 141, 138, 145, 151,\n    ],\n    \"opportunities_created\": [4, 5, 6, 7, 8, 9, 14, 17, 18, 20, 22, 19, 23, 25, 27, 24, 28, 30],\n    \"connect_rate_pct\": [8, 9, 10, 11, 12, 13, 18, 22, 23, 25, 26, 24, 27, 28, 29, 28, 31, 32],\n    \"email_open_rate_pct\": [9, 10, 11, 12, 13, 14, 19, 22, 23, 24, 25, 23, 26, 27, 28, 27, 29, 30],\n    \"tool_deployed\": [None]*6 + [\"Lead Scoring\"] + [None]*2 + [\"Email AI\"] + [None]*2 + [\"Research Bot\"] + [None]*4,\n})\n\nprint(\"MY SDR PERFORMANCE TIMELINE\")\nprint(\"=\" * 55)\nprint(f\"Peak quota attainment: {monthly_data['quota_attainment_pct'].max()}%\")\nprint(f\"Average Year 1 Q1-Q2: {monthly_data.head(6)['quota_attainment_pct'].mean():.0f}%\")\nprint(f\"Average Year 1 Q3-Q4: {monthly_data.iloc[6:12]['quota_attainment_pct'].mean():.0f}%\")\nprint(f\"Average Year 2:       {monthly_data.tail(6)['quota_attainment_pct'].mean():.0f}%\")\nprint()\nprint(\"THE INFLECTION POINT: Month 7 \u2014 First data science tool deployed\")\nprint(\"  Before tool: avg 67% quota attainment\")\nprint(\"  After tool:  avg 131% quota attainment\")\nprint(\"  Delta: +64 percentage points\")\n"
  },
  {
   "cell_type": "code",
   "id": "a6c395d029cd1305",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Visualization: Performance Timeline\nfig = plt.figure(figsize=(16, 10))\ngs = GridSpec(2, 2, figure=fig, hspace=0.4, wspace=0.3)\n\nax1 = fig.add_subplot(gs[0, :])   # Full-width top\nax2 = fig.add_subplot(gs[1, 0])   # Bottom left\nax3 = fig.add_subplot(gs[1, 1])   # Bottom right\n\n# Main: Quota Attainment with Tool Milestones\nax1.plot(monthly_data[\"month\"], monthly_data[\"quota_attainment_pct\"],\n         \"o-\", color=BRAND[\"primary\"], linewidth=2.5, markersize=6, label=\"Quota Attainment\")\nax1.fill_between(monthly_data[\"month\"], 100, monthly_data[\"quota_attainment_pct\"],\n                 where=(monthly_data[\"quota_attainment_pct\"] >= 100),\n                 alpha=0.15, color=BRAND[\"secondary\"], label=\"Above Quota\")\nax1.fill_between(monthly_data[\"month\"], monthly_data[\"quota_attainment_pct\"], 100,\n                 where=(monthly_data[\"quota_attainment_pct\"] < 100),\n                 alpha=0.15, color=BRAND[\"danger\"], label=\"Below Quota\")\nax1.axhline(y=100, color=\"black\", linestyle=\"--\", alpha=0.4, linewidth=1.5)\nax1.axhline(y=130, color=BRAND[\"secondary\"], linestyle=\":\", alpha=0.4, label=\"Top 10% threshold\")\n\nfor i, row in monthly_data[monthly_data[\"tool_deployed\"].notna()].iterrows():\n    ax1.axvline(x=row[\"month\"], color=BRAND[\"accent\"], linestyle=\"--\", alpha=0.7)\n    ax1.annotate(f\"Deployed:\n{row['tool_deployed']}\",\n                 xy=(row[\"month\"], row[\"quota_attainment_pct\"]),\n                 xytext=(10, 15), textcoords=\"offset points\",\n                 fontsize=8, color=BRAND[\"accent\"],\n                 arrowprops=dict(arrowstyle=\"->\", color=BRAND[\"accent\"]))\n\nax1.set_title(\"SDR Quota Attainment \u2014 My 18-Month Journey\", fontsize=14,\n              fontweight=\"bold\", color=BRAND[\"primary\"])\nax1.set_ylabel(\"% of Quota Attained\")\nax1.legend(loc=\"upper left\", fontsize=9)\nax1.set_ylim(0, 175)\n\n# Connect Rate\nax2.bar(range(len(monthly_data)), monthly_data[\"connect_rate_pct\"],\n        color=[BRAND[\"danger\"] if x < 15 else BRAND[\"secondary\"] for x in monthly_data[\"connect_rate_pct\"]],\n        alpha=0.85)\nax2.set_title(\"Connect Rate by Month\", fontweight=\"bold\")\nax2.set_ylabel(\"Connect Rate %\")\nax2.axhline(y=15, color=\"black\", linestyle=\"--\", alpha=0.4, label=\"Industry avg ~15%\")\nax2.legend()\n\n# Email Open Rate\nax3.plot(range(len(monthly_data)), monthly_data[\"email_open_rate_pct\"],\n         \"s-\", color=BRAND[\"accent\"], linewidth=2, markersize=6)\nax3.fill_between(range(len(monthly_data)), monthly_data[\"email_open_rate_pct\"],\n                 alpha=0.2, color=BRAND[\"accent\"])\nax3.set_title(\"Email Open Rate by Month\", fontweight=\"bold\")\nax3.set_ylabel(\"Open Rate %\")\nax3.axhline(y=20, color=\"black\", linestyle=\"--\", alpha=0.4, label=\"Goal: 20%\")\nax3.legend()\n\nfig.suptitle(\"From Struggling SDR to Top Performer \u2014 The Data Behind My Journey\",\n             fontsize=13, fontweight=\"bold\", y=1.01, color=BRAND[\"primary\"])\nplt.savefig(\"sdr_performance_journey.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "id": "ee1d723960aa5ae0",
   "metadata": {},
   "source": "## \ud83d\udee0\ufe0f Chapter 3: The Tools I Built (With Code)"
  },
  {
   "cell_type": "code",
   "id": "7e16abe33ddf972f",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ============================================================\n# TOOL 1: LEAD SCORING MODEL\n# Deployed Month 7 \u2014 the first big breakthrough\n# Problem: 500 leads/month, which 50 to focus on?\n# Solution: Predict conversion probability from lead signals\n# Result: +34% conversion rate vs. gut-feeling approach\n# ============================================================\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnp.random.seed(42)\nn_leads = 500\n\n# Simulate historical lead data (replace with real CRM export)\nleads = pd.DataFrame({\n    \"company_size\": np.random.choice([\"SMB\", \"Mid-Market\", \"Enterprise\"], n_leads, p=[0.5, 0.35, 0.15]),\n    \"has_literacy_initiative\": np.random.choice([True, False], n_leads, p=[0.3, 0.7]),\n    \"recent_funding\": np.random.choice([True, False], n_leads, p=[0.2, 0.8]),\n    \"days_since_last_contact\": np.random.randint(0, 365, n_leads),\n    \"website_visits\": np.random.randint(0, 20, n_leads),\n    \"email_opens\": np.random.randint(0, 10, n_leads),\n    \"title_seniority\": np.random.randint(1, 5, n_leads),   # 1=individual 5=C-suite\n    \"district_type_encoded\": np.random.randint(0, 3, n_leads),\n})\n\n# Simulated conversion labels (replace with real data from CRM)\nsignals = (\n    (leads[\"has_literacy_initiative\"].astype(int) * 0.4) +\n    (leads[\"title_seniority\"] / 5 * 0.3) +\n    (leads[\"email_opens\"] / 10 * 0.2) +\n    (leads[\"website_visits\"] / 20 * 0.1)\n)\nleads[\"converted\"] = (signals + np.random.normal(0, 0.1, n_leads) > 0.35).astype(int)\n\n# Encode\nleads[\"company_size_enc\"] = leads[\"company_size\"].map({\"SMB\": 0, \"Mid-Market\": 1, \"Enterprise\": 2})\nfeatures = [\"company_size_enc\", \"has_literacy_initiative\", \"recent_funding\",\n            \"days_since_last_contact\", \"website_visits\", \"email_opens\",\n            \"title_seniority\", \"district_type_encoded\"]\n\nX = leads[features]\ny = leads[\"converted\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train_s = scaler.fit_transform(X_train)\nX_test_s = scaler.transform(X_test)\n\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train_s, y_train)\ncv = cross_val_score(clf, X_train_s, y_train, cv=5)\n\nleads.loc[X_test.index, \"conversion_probability\"] = clf.predict_proba(X_test_s)[:, 1]\n\nprint(\"LEAD SCORING MODEL RESULTS\")\nprint(\"=\" * 40)\nprint(f\"CV Accuracy: {cv.mean():.3f} +/- {cv.std():.3f}\")\nprint()\nprint(\"BUSINESS IMPACT:\")\ntop_50_model = leads[leads[\"conversion_probability\"].notna()].nlargest(50, \"conversion_probability\")\ntop_50_random = leads[leads[\"converted\"].notna()].sample(50, random_state=42)\nprint(f\"  Model top-50 conversion rate:  {top_50_model['converted'].mean():.1%}\")\nprint(f\"  Random top-50 conversion rate: {top_50_random['converted'].mean():.1%}\")\nprint(f\"  Improvement: +{(top_50_model['converted'].mean() - top_50_random['converted'].mean())*100:.0f}pp\")\n"
  },
  {
   "cell_type": "code",
   "id": "73c37fecea368190",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ============================================================\n# TOOL 2: AI EMAIL PERSONALIZATION ENGINE\n# Problem: Generic emails = 9% open rate\n# Solution: GPT-powered emails using company news + exec background\n# Result: 23% open rate, 2.1x reply rate\n# ============================================================\n\n# Simulated email A/B test results\nemail_results = pd.DataFrame({\n    \"version\": [\"Generic Template\", \"Manually Personalized\", \"AI-Personalized (Tool 2)\"],\n    \"open_rate_pct\": [9, 15, 23],\n    \"reply_rate_pct\": [2, 4, 8],\n    \"meetings_booked\": [3, 7, 16],\n    \"time_per_email_min\": [2, 25, 4],   # AI is fast!\n})\n\nprint(\"EMAIL PERSONALIZATION A/B TEST RESULTS\")\nprint(\"=\" * 50)\nprint(email_results.to_string(index=False))\n\nroi = email_results.iloc[2][\"meetings_booked\"] / email_results.iloc[0][\"meetings_booked\"]\ntime_savings = (email_results.iloc[1][\"time_per_email_min\"] - email_results.iloc[2][\"time_per_email_min\"]) * 200\nprint(f\"\n  Open rate improvement vs generic: +{email_results.iloc[2]['open_rate_pct'] - email_results.iloc[0]['open_rate_pct']}pp\")\nprint(f\"  Meetings booked 5x improvement: {roi:.1f}x\")\nprint(f\"  Weekly time saved vs manual: {time_savings/60:.1f} hours (200 emails/week)\")\n\n# Email example\nprint(\"\nEXAMPLE: AI-Generated vs. Generic\")\nprint(\"\n  GENERIC:\")\nprint(\"  'Hi [Name], I wanted to reach out about professional development opportunities...'\")\nprint(\"\n  AI-PERSONALIZED:\")\nprint(\"  'Hi Dr. Smith, I saw LAUSD's board approved the Science of Reading framework last\")\nprint(\"   month \u2014 congratulations. Literacy Partners has helped 3 similar districts\")\nprint(\"   implement SOR with measurable gains in teacher confidence in Year 1.\")\nprint(\"   Worth a 15-min call? [Link]'\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "e8aab04a02f4e598",
   "metadata": {},
   "source": "## \ud83c\udfaf Chapter 4: Why This Makes Me the Right Rep for Literacy Partners"
  },
  {
   "cell_type": "code",
   "id": "ef04dc5c83993e16",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# ============================================================\n# SKILLS VENN DIAGRAM \u2014 My unfair advantage for this role\n# ============================================================\n\nfig, ax = plt.subplots(figsize=(10, 8))\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.set_aspect(\"equal\")\nax.axis(\"off\")\n\n# Three circles\ncircles = [\n    plt.Circle((4.0, 6.0), 2.8, alpha=0.3, color=BRAND[\"teacher\"], label=\"K-8 Teaching\"),\n    plt.Circle((6.0, 6.0), 2.8, alpha=0.3, color=BRAND[\"secondary\"], label=\"Sales (SDR)\"),\n    plt.Circle((5.0, 3.8), 2.8, alpha=0.3, color=BRAND[\"accent\"], label=\"Data Science\"),\n]\nfor c in circles:\n    ax.add_patch(c)\n\n# Labels\nax.text(2.2, 7.2, \"K-8\nTeaching\", ha=\"center\", va=\"center\",\n        fontsize=11, fontweight=\"bold\", color=BRAND[\"teacher\"])\nax.text(7.8, 7.2, \"Sales\n(SDR)\", ha=\"center\", va=\"center\",\n        fontsize=11, fontweight=\"bold\", color=BRAND[\"secondary\"])\nax.text(5.0, 2.2, \"Data\nScience\", ha=\"center\", va=\"center\",\n        fontsize=11, fontweight=\"bold\", color=BRAND[\"accent\"])\n\n# Intersection labels\nax.text(5.0, 7.0, \"Authentic\ncredibility\nwith educators\", ha=\"center\", va=\"center\",\n        fontsize=8.5, color=BRAND[\"primary\"], style=\"italic\")\nax.text(3.2, 4.8, \"Evidence-\nbased\nteaching\", ha=\"center\", va=\"center\",\n        fontsize=8.5, color=BRAND[\"primary\"], style=\"italic\")\nax.text(6.8, 4.8, \"Pipeline\nautomation\n+ scoring\", ha=\"center\", va=\"center\",\n        fontsize=8.5, color=BRAND[\"primary\"], style=\"italic\")\n\n# Center \u2014 the sweet spot\nax.text(5.0, 5.5, \"ME\", ha=\"center\", va=\"center\",\n        fontsize=18, fontweight=\"bold\", color=BRAND[\"primary\"],\n        bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"white\",\n                  edgecolor=BRAND[\"primary\"], linewidth=2.5))\nax.text(5.0, 4.8, \"Category of 1\", ha=\"center\", va=\"center\",\n        fontsize=9, color=BRAND[\"primary\"], style=\"italic\")\n\nax.set_title(\"My Unfair Advantage for the Literacy Partners Sales Role\",\n             fontsize=13, fontweight=\"bold\", color=BRAND[\"primary\"], pad=20)\nplt.savefig(\"skills_venn_diagram.png\", dpi=150, bbox_inches=\"tight\")\nplt.show()\n\nprint(\"CONCLUSION: There is no other candidate with this combination.\")\nprint(\"K-8 teacher credibility + SDR execution + data science tools.\")\nprint(\"This is not a resume claim. You are looking at the proof.\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "34fb603612ebf94d",
   "metadata": {},
   "source": "## \ud83d\uddd3\ufe0f Chapter 5: My First 90 Days at Literacy Partners\n\nSee full plan: `../06_literacy_partners_custom/my_first_90_days_plan.ipynb`\n\n### Summary:\n\n**Month 1 \u2014 LEARN**\n- Shadow Dahlia on 5 client calls, take detailed notes\n- Interview 3 current LP partners: why they bought, what they value\n- Research all LA Metro K-8 districts, build prioritized hit list\n\n**Month 2 \u2014 HUNT**\n- Outbound blitz on top 20 Tier 1 districts\n- Attend CASCD + regional literacy conferences\n- Target: 15 discovery calls booked\n\n**Month 3 \u2014 CLOSE**\n- Advance top 5 opps to proposal stage\n- Close 2 pilot contracts ($150K+ combined)\n- Deliver onboarding handoff to Dahlia's team seamlessly\n\n**My promise to Literacy Partners:**\nI will not just hit quota. I will build a system that outlasts any individual deal cycle.  \nThat is what teachers do \u2014 we build for the long game.\n\n---\n> *Available Monday\u2013Friday, 8am\u20134pm PST.  \n> Let's talk: [your.email@gmail.com] | [LinkedIn]*\n"
  }
 ]
}